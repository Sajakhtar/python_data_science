{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neural Nets, Deep Learning, Tensorflow\n",
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Installation\n",
    "\n",
    "Installing Tensoreflow:\n",
    "\n",
    "    conda install -c conda-forge tensorflow\n",
    "    \n",
    "    \n",
    "Or use Google Colab: https://colab.research.google.com/notebooks/intro.ipynb\n",
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Slides:\n",
    "\n",
    "https://docs.google.com/presentation/d/12oUP2g7gqpPBdZcmzuqH8_ttnzosOKA2cZKbOFJyPKU/edit#slide=id.g73ebe5debd_0_7\n",
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Introduction to Artificial Neural Networks (ANN)\n",
    "\n",
    "**Theory:**\n",
    "* Perception Model to Neural Networks\n",
    "* Activation Functions\n",
    "* Cost Functions\n",
    "* Feed Forward Networks\n",
    "* Backpropagation\n",
    "\n",
    "___\n",
    "\n",
    "**Coding:**\n",
    "* TensorFlow 2.0 Keras Syntax\n",
    "* ANN with Keras\n",
    "    * Regression\n",
    "    * Classification\n",
    "* Exercises for Keras ANN\n",
    "* Tensorboard Visualizations\n",
    "\n",
    "___\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Deep Learning model abstractions\n",
    "    * Single Biological Neuron\n",
    "    * Perceptron\n",
    "    * Multi-layer Perception Model\n",
    "    * Deep Learning Neural Network\n",
    "\n",
    "\n",
    "* Mathematical concepts\n",
    "    * Activation Functions\n",
    "    * Gradient Descent\n",
    "    * Backpropagation\n",
    "\n",
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Perceptron Model\n",
    "\n",
    "* Idea behind deep learning is to have computers artificially mimic biological natural intelligence, we should probably build a general understanding of how biological neurons work\n",
    "* Stained Neurons in a cerebral cortex\n",
    "* build a simple abstraction of how biological neurons work\n",
    "* simplify a neuron to\n",
    "    * dendrites are inputs with  in to nucleus\n",
    "    * nucleus does some calculation\n",
    "    * axons is a single output from the nucleus\n",
    "* This translates to\n",
    "    * x1 and x2 as inputs with weights w1 and w2, in to nucleus\n",
    "        * adjust weights as neccessary to get correct value of y\n",
    "    * function f(x) in nucleus\n",
    "    * single output y from the nucleus\n",
    "    * add a bias term in case x inputs are zero\n",
    "    * the product of x and its w have to overcome the bias value to have an effect on the output y\n",
    "    * y = (x1w1 + b1) + (x2w2 + b2) + ... + (xnwn + b)\n",
    "    * \\begin{equation*} \\hat{y} = \\sum_{i=1}^n x_{i}w_{i} + b_{i} \\end{equation*}\n",
    "    * This model can be expanded to have x be a tensore (n-dimensional matrix)\n",
    "* A perceptron was a form of neural network introduced in 1958 by Frank Rosenblatt\n",
    "* \"...perceptron may eventually be able to learn, make decisions, and translate languages\"\n",
    "* 1969, Marvin Minsky and Seymour Papert's published their book Perceptions\n",
    "    * it suggested that there were severe limitations to what perceptrons could do\n",
    "    * biggest limitation was computational power\n",
    "    * this marked the beginning of the *AI Winter*, with little funding into AI and Neural Networks in 1970s\n",
    "___\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Neural Networks\n",
    "\n",
    "* A single perceptron won't be enough to learn complicated systems\n",
    "* We can expand on the idea of a single perceptron, to create a multi-layer perceptron model\n",
    "    * commonly known as a basic artificial neural network (ANN)\n",
    "* To build a network of perceptrons, we can connect layers of perceptrons, using a multi-layer perceptron model\n",
    "    * perceptron is the same as neuron\n",
    "    * output of previous layer becomes input of the next layer\n",
    "        * outputs of one perceptron (neuron) are directly fed into inputs of another perceptron\n",
    "    * fully connected layer, if a neuron (perceptron) in a given layer connects to *all* neurons in the subsequent layer**\n",
    "* This allows the network as a whole to learn about iteractions and relationships between features\n",
    "* The first layer is the input layer\n",
    "    * this layer receives data e.g. tabular data with features from which we're trying to predict the label off\n",
    "* The last layer is known as the output layer\n",
    "    * this can be more than one neuron especially when dealing with multi-class classification\n",
    "* Layers between the input and output layers are the hidden layers\n",
    "    * hidden layers are difficult to interpret, due to their high interconnectivity and distance away from known input or output values\n",
    "    * basically a black box\n",
    "* Neural Networks become **\"deep neural networks\"** if they contain 2 or more hidden layers\n",
    "* Width of a network = how many neurons in a layer\n",
    "* depth of a network = how many layers in total\n",
    "* Neural Network framework can be used to approximate any function\n",
    "    * Zhou Lu and Boris Hanin proved mathematically that Neural Networks can approximate any convex continuous function\n",
    "    * https://en.wikipedia.org/wiki/Universal_approximation_theorem\n",
    "\n",
    "___\n",
    "\n",
    "* In the simple perceptron model, the perceptron contained a very simple summation function f(x)\n",
    "* For must use cases that won't be useful\n",
    "* We'll want to be able to set constraints, not a simple sum, to our output values especially in classification tasks\n",
    "* In classification tasks, it would be usefule to have all outputs fall between 0 and 1\n",
    "    * which will a probability assignment for each class\n",
    "* **Activation functions** set boundaries to output values from the neuron\n",
    "\n",
    "___\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Activation Functions\n",
    "\n",
    "* Recall that inputs **x** have a weight **w** and a bias term **b** in the perceptron model\n",
    "* **x*w + b**\n",
    "* **w** implies how much weight or strength ot give the incoming input\n",
    "* think of **b** as an offset value, making **x*w** have to reach a certain threshold before having an effect\n",
    "* We want to set boundaries for the output value of **x*w + b**\n",
    "* to keep things simple let's say **z = x*w + b**\n",
    "* then **z** passes through some ***activation function*** to limit its value\n",
    "* A lot of research has been done into activation functions and their effectiveness\n",
    "* some **common activation functions**:\n",
    "    * For binary classification \n",
    "        * If we had a binary classification problem we would want an output **y** of 0 or 1 from our perceptron model (y = (x1w1 + b1) + ... + (xnwn + b))\n",
    "        * **z = wx + b**\n",
    "        * then activation function is **f(z)**\n",
    "            * varibales are capitalized for *tensor* inputes to denote multiple values i.e. **f(Z)** and **X**\n",
    "        * The most simple networks rely on a basic **step function** that outputs 0 or 1\n",
    "        * so if **z < 0** output is 0 and if **z > 0** output is 1\n",
    "        * But this is a strong function, since small changes are not reflected\n",
    "        * A more dynamic function would be the **sigmoid function** (aka **logisitic function**)\n",
    "            * \\begin{equation*} f(z) = \\frac{1}{1 + e^{(-z)}} \\end{equation*}\n",
    "            * where z = wx + b\n",
    "            * values can range between 0 and 1 and can be treated as a probability of belonging to a particular class\n",
    "    * other common activation functions:\n",
    "        * **Hyperbolic Tangent: tanh(z)**\n",
    "            * Outputs value between -1 and 1\n",
    "            * Useful in certain circumstances thta will be mentioned later\n",
    "            * \\begin{equation*} tanh(z) = \\frac{sinh(z)}{cosh(z)} \\end{equation*}\n",
    "            * \\begin{equation*} cosh(z) = \\frac{e^x + e^{-x}}{2} \\end{equation*}\n",
    "            * \\begin{equation*} sinh(z) = \\frac{e^x - e^{-x}}{2} \\end{equation*}\n",
    "        * **Rectified Linear unit (ReLu)**\n",
    "            * relatively simple function: **maz(0,z)**\n",
    "            * if the output of z = wx + b is less than 0, then treat as 0\n",
    "            * else, output the actual z value\n",
    "            * ReLu has been to have good performance, especially when dealing with **vanishing gradient**\n",
    "            * ReLU is commonly used in literature\n",
    "            * We'll default to ReLu when building networks, due to its overall good performance\n",
    "        * Full list of activaiton functions https://en.wikipedia.org/wiki/Activation_function\n",
    "        * **Softmax** activation function for multi-class classfication\n",
    "* Activation function equation's ***derivative*** is imporantant for backpropagation\n",
    "            \n",
    "___\n",
    "            "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multi-Class Classification Considerations\n",
    "\n",
    "* Previously discussed activation functions make sense for a single output\n",
    "    * predicting a continuous function\n",
    "    * predicting a binary classification (0 or 1)\n",
    "* In multi-class situation the output layer of the neural net will have multiple neurons\n",
    "* 2 main types of multi-class situation\n",
    "    * Non-Execlusive Classes\n",
    "        * A data point can have multiple classes/ categories assigned to it\n",
    "        * Photos can have multiple tags e.g. beach, family, vaction, ...\n",
    "    * Mutually Exclusive Classes\n",
    "        * Only one class per data point\n",
    "        * more common type in ML\n",
    "        * Photos can be categorized as being in grayscale or full-color, but can't be both at the same time\n",
    "* Organizing data that contains Multiple Classes\n",
    "    * easiest way to organize multiple classes is to simply have 1 output neuron per class\n",
    "    * this means we need to organize categories for this output layer\n",
    "    * we can't just have categories like 'red', 'blue', 'green', etc...\n",
    "    * instead we use **one-hot encoding** aka creating **dummy variables**\n",
    "        * Mutually Exclusive Classes\n",
    "            * classes red', 'blue', 'green'\n",
    "            * do binary classification for each class, to build out a matrix\n",
    "                * red', 'blue', 'green'as columns\n",
    "                * with a value of 0 or 1 for each data point/row in the revelvant column\n",
    "                * for a given data point, only one column has a value of 1, all other cols will be 0 \n",
    "        * Non-Execlusive Classes\n",
    "            * do binary classification for each class, to build out a matrix\n",
    "            * a column for each classes \n",
    "            * with a value of 0 or 1 for each data point/row in the revelvant columns\n",
    "            * but in this case for a given data point, there can be more than one value of 1 classification across the columns (classes)\n",
    "* **Activitation functions for output layer**\n",
    "    * **for Non-Execlusive Classes use *Sigmoid Function***\n",
    "        * each neuron will output a vlaue between 0 and 1, indicating the probability of having that class assigned to it\n",
    "        * you might assign two classes (tags) where the sigmoid function is greater than the cut-off point (threshold)\n",
    "        * If the cutoff point is 0.5, the output layer has 5 neurons (5 classes) and sigmoid function for 2 neurons in the output layer are above this, then those 2 classes would be assigned to the data point \n",
    "        * keep in mind this allows each neuron to output independently of the other classes, allowing for a single data point to be fed into the function to have multiple classes assigned to it\n",
    "    * **for Mutually Exclusive Classes use *Softmax Function***\n",
    "        * \\begin{equation*} \\sigma(Z)_{i} = \\frac{e^{z_{i}}}{\\sum_{j=1}^K e^{z_{j}}} \\;for\\;i = 1, ..., K\\end{equation*}\n",
    "        * K = number of categories\n",
    "        * softmax functions calculates the probabilities distribution of the event over K different events\n",
    "        * This functions will calculate the probabilities of each target class over all possible target classes\n",
    "        * The range will be 0 to 1, and the **sum of all the probabilities will be equal to 1** \n",
    "        * the model returns the probabilities of each class and the target class chosen will be the one with the highest probability\n",
    "\n",
    "\n",
    "            \n",
    "\n",
    "____"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cost Functions and Gradient Descent\n",
    "\n",
    "* We now understand that neural networks take in inputs, multiply them by weights and add biases to them\n",
    "* This result is passed through an activation functions which at the end of all the layers leads to some output\n",
    "* This output layer, \\$\\hat{y}\\$, is the model's estimation of what it predicts the label to be\n",
    "* Questions\n",
    "    * *After the network creates its predictions, how do we evaluate it against the true label?*\n",
    "        * Minimize the cost functions\n",
    "    * *And after the evaluation, how can we update the network's weights and biases?*\n",
    "        * Backpropagation\n",
    "\n",
    "\n",
    "* **Cost Functions (aka loss functions or error functions)**\n",
    "    * we need to take the estimated outputs of the network and then compare them to the real values of the label\n",
    "        * using the training dataset during fitting/training of the model\n",
    "    * cost function simply measures how far off the prediction is from the true labels\n",
    "    * cost function must be an average so it can output a single value\n",
    "    * we can keep track of the loss/cost during the training to monitor the network performance\n",
    "    * during each epoch of training the loss/cost goes down until it converges to a minimum value\n",
    "    * \\$y\\$ = the true value\n",
    "    * \\$a\\$ = the neurons prediction\n",
    "    * \\$wx + b = z\\$\n",
    "    * pass \\$z\\$ into activation function \\$\\sigma(z) = a\\$\n",
    "    * \\$a\\$ holds information about the activation function, weights and biases\n",
    "    * one very commone cost function is the **quadratic cost function** (essentiallly Root Mean Squared Error, RMSE, notated for multidimentional data)\n",
    "        * \\$C=\\frac{1}{2n}\\sum_{x}\\parallel y(x)-a^L(x) \\parallel^2\\$\n",
    "        * where \\$L\\$ is the last layer (prior layers are \\$L-1\\$, \\$L-2\\$,... - working backwards)\n",
    "        * and \\$n\\$ is number of training points\n",
    "        * we simply calculate the difference between the real values \\$y(x)\\$ against our predicted values \\$a(x)\\$\n",
    "        * Note:\n",
    "            * the notation show here corresponds to the vector inputs and outputs, since we will be dealing with a **batch** of training points and predictions\n",
    "            * notice how squaring this does 2 useful things\n",
    "                * keeps everything postive\n",
    "                * punishes large errors!\n",
    "        * Think of cost function of 4 main things \\$C(W,B,^*r,E^r)\\$\n",
    "            * \\$W\\$ = neural network weights\n",
    "            * \\$B\\$ = neural network's biases\n",
    "            * \\$S^r\\$ = input of a single training sample\n",
    "            * \\$E^r\\$ = desired output of the training sample\n",
    "            * all this information is encoded in the formula\n",
    "                * \\$a(x)\\$ holds information on weights, biases, inputs\n",
    "        * if we have a huge network, we can expect \\$C\\$ to be quite complex, with huge vector (tensor) or weights and biases\n",
    "        * In a real case, this means we have some cost function \\$C\\$ dependent on lots of weights \\$C(w1,w2,...wn)\\$\n",
    "            * How do we figure out which weights lead us to the lowest cost?\n",
    "            * for simplicity, imagine we only had one weight in our cost function \\$w\\$\n",
    "            * we want to **minimize** our loss/cost (overall error)\n",
    "            * which means we need ot igure out what value of \\$w\\$ results in the minimum of \\$C(w)\\$\n",
    "            * to find the \\$w\\$, we could take the derivitive of the the cost function \\$C(w)\\$ and solve for 0, but our real cost function will be very complex (multi-dimensional) - it will be n-dimensional since our networks will have 1000s of weights\n",
    "            * So, we need to use a *stochastic* process such as **gradient descent**\n",
    "* **Gradient descent**\n",
    "    * start off at one point for \\$w\\$ on the cost function \\$C(w)\\$ curve\n",
    "    * calculate the slope at that point\n",
    "    * move the point in the downward direction of the slope\n",
    "    * keep repeating the process until we converge to zero, indicating the minimum \\$w_{min}\\$\n",
    "    * we can move the point in different step sizes\n",
    "        * smaller step sizes take longer to find the minimum\n",
    "        * larger steps are faster, but we risk overshooting the minimum\n",
    "        * step size is known as the **learning rate** i.e. how fast we're going to try to find the min value\n",
    "        * We could start with larger steps, then go smaller as we realize the slope gets closer to zero aka **adaptive gradient descent** i.e. adapt step size\n",
    "    * 2015, Kingma and Ba paper: \"Adam: A method for Stochasitc Optimization\"\n",
    "        * Adam is a much more efficient way of searching for these minimums, so we'll Adam as our optimizer it in our code for gradient descent\n",
    "        * Adam outperforms other adaptive gradient descent algorithms, such as AdaGrad, RMSProp, SGDNesterov, AdaDelta\n",
    "    * When dealing with N-dimensional vectors (tensors), the notation (correct phrase) changes from **derivative** to **gradient**\n",
    "    * This means we calculate the gradient of the cost function with respect to all the weights \\$ \\bigtriangledown C(w1,w2,...wn)\\$\n",
    "* For **classification problems**, we often use the **cross entropy** loss function\n",
    "    * the assumption is that the model predicts a probability distribution \\$p(y=i)\\$ for each class \\$i=1,2,...,C\\$\n",
    "    * for binary classification the probability distribution is:\n",
    "        * \\$-(y\\log(p) + (1-y) \\log(1-p)\\$\n",
    "    * for \\$M\\$ number of classes > 2, the probability distribution is:\n",
    "        * \\$ - \\sum_{c=1}^M y_{o,c}\\log(p_{o,c})\\$\n",
    "* Once we get our cost/loss vlaue, how do we actually go back and adjust our weights and biases?\n",
    "    * **backpropagation**\n",
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Backpropagation\n",
    "\n",
    "* Backpropagation is a difficult calculus heavy topic\n",
    "* basic idea is that you move backwards through network to update the wieghts and biases\n",
    "* Fundamentally, we want to knonw how the cost function results changes wrt the weights in the network, so we can update the weights to minimize the cost functions\n",
    "* Consider a network with 1 neuron per palyer and 4 layers\n",
    "    * Cost function \\$C(w1,b1,w2,b2,w3,b3,w4,b4)\\$\n",
    "    * Layer notation: L = last layer, L-1, L-2, L-n\n",
    "    * Backprogation starts in last layer \\$L\\$, once we've gone through our feed forward process \n",
    "    * focusing on last 2 layers, \\$L\\$ and \\$L-1\\$\n",
    "    * define \\$z=wx+b\\$, where x is the raw input (features) so only applies at the first layer\n",
    "    * as you move forward to the next layer, \\$x\\$ technically becomes the outpput from the previous layer, which is the output from the activation function \\$a=\\sigma(z)\\$\n",
    "    * then applying an activation function we'll state \\$a=\\sigma(z)\\$\n",
    "    * this means \\$z\\$ at last layer is \\$z^L=w^La^{L-1}+b^L\\$\n",
    "        * (see that we've replaced \\$x\\$ with \\$a^{L-1}\\$, which is the output from the previous layer)\n",
    "    * this means we have \\$a^L = \\sigma(z^L)\\$\n",
    "    * and so the cost function \\$C_{0}=(a^L - y)^2\\$\n",
    "    * What we want to understand is how sensitive is the cost function to changes in \\$w\\$:\n",
    "        * this is where parial derivatives come in: \\$\\frac{\\delta C_{0}}{\\delta w^L}\\$\n",
    "        * the partial derivative with respects to weights and cost function at layer \\$L\\$\n",
    "        * using the calculus **chain rule** to take the derivative of a function within a function: \\$\\frac{\\delta C_{0}}{\\delta w^L} = \\frac{\\delta z^L}{\\delta w^L} \\frac{\\delta a^L}{\\delta z^L} \\frac{\\delta C_{0}}{\\delta a^L}\\$\n",
    "            * we can determine that the partial derivative of tha cost function wrt that weight is equal to\n",
    "                * partial derivative of the \\$z\\$ wrt that weight\n",
    "                * mutliplied by partial derivative of the \\$a\\$ wrt \\$z\\$\n",
    "                * mutliplied by partial derivative of the cost function wrt \\$a\\$\n",
    "    * Cost function is not just a function of the weights, but biases as well, so we can calculate the same for the biases as well: \\$\\frac{\\delta C_{0}}{\\delta b^L} = \\frac{\\delta z^L}{\\delta b^L} \\frac{\\delta a^L}{\\delta z^L} \\frac{\\delta C_{0}}{\\delta a^L}\\$\n",
    "    * The main idea here is that we can use the gradient to go back through the network and adjust our weights and biases to minimize the output of the error vector on the last output layer\n",
    "    * Using some calculus notation, we can expand this idea to netowrks with multiple neurons per layer\n",
    "    * Hadamard Product:\n",
    "        * \\$\\begin{bmatrix} 1 \\\\ 2 \\end{bmatrix} \\odot \\begin{bmatrix} 3 \\\\ 4 \\end{bmatrix} = \\begin{bmatrix} 1*3 \\\\ 2*4 \\end{bmatrix} =  \\begin{bmatrix} 3 \\\\ 8 \\end{bmatrix}\\$\n",
    "        * basically element by element multiplication that Pandas does for us\n",
    "* Given this notation and backpropagation, we have a few main steps to training neural networks\n",
    "    * *Step 1:* Using input \\$x\\$ set the activation function \\$a\\$ for the input layer\n",
    "        * \\$z=wx+b\\$\n",
    "        * \\$a=\\sigma(z)\\$ sigmoid of \\$z\\$\n",
    "        * this resulting \\$a\\$ feeds into the next layer and so on\n",
    "            * where the enxt layer's \\$z\\$ is \\$z=wa+b\\$\n",
    "    * *Step 2:* for each layer, compute:\n",
    "        * \\$z^L=w^La^{L-1}+b^L\\$\n",
    "        * \\$a^L=\\sigma(z^L)\\$\n",
    "    * *Step 2:* we compute our error vector:\n",
    "        * \\$\\delta=\\bigtriangledown_{a}C\\odot\\sigma'(z^L)\\$\n",
    "            * \\$\\bigtriangledown_{a}C=(a^L-y)\\$\n",
    "            * expressing the rate of change of the cost function wrt the output activations\n",
    "        * $\\delta=(a^L-y)\\odot\\sigma'(z^L)\\$\n",
    "        * we want to write a generalized error vector formula in terms of the next layer, since we're moving backwards\n",
    "        * (\\$L\\$ denoste output layer, lowercase \\$l\\$ for prior layers)\n",
    "    * *Step 4:* backpropagate the error\n",
    "        * for each layer: L-1, L-2,... we compute\n",
    "            * \\$\\delta^l=(w^{l+1})^T\\delta^{l+1}\\odot\\sigma'(z^l)\\$\n",
    "            * \\$(w^{l+1})^T\\$ is the transpose of the weight matrix of \\$l+1\\$ layer\n",
    "        * when we apply the transpose weight matrix \\$(w^{l+1})^T\\$, we can think intuitively of this as moving the error backwards through the network, giving us some sort of measure of the error at the output of the \\$l\\$th layer\n",
    "        * we then take the Hadamard product \\$\\odot\\sigma'(z^l)\\$ - this moves the error backaward through the activation function in layer \\$l\\$, giving us the error \\$\\delta^l\\$ in the weighted input to layer \\$l\\$\n",
    "        * The gradient of the cost function is given by:\n",
    "            * For each layer: L-1, L-2,... we compute partial derivatives of the cost function wrt the weights and biases\n",
    "                * \\$\\frac{\\delta C}{\\delta w_{jk}^l} = a_{k}^{l-1}\\delta_{j}^l\\$\n",
    "                * \\$\\frac{\\delta C}{\\delta b_{j}^l} = \\delta_{j}^l\\$\n",
    "                * where \\$j\\$ and \\$k\\$ is the notations for the neurons themselves\n",
    "             * This then allows us to adjust the weights and biases to help minimize that cost functions\n",
    "             \n",
    "___"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
